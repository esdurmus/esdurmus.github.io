<img src="esin.jpeg" alt="esin" style="width:10cm;"/>

**Contact:** esindurmus AT cs DOT stanford DOT edu



[<a href="https://scholar.google.com/citations?user=cq2R_uoAAAAJ&hl=en">Google Scholar</a>] [<a href="https://www.semanticscholar.org/author/Esin-Durmus/41152329">Semantic Scholar</a>]
[<a href="cv_esin_durmus.pdf">CV</a>]

<h2>I am on the job market!</h2>

Hi! I am Esin Durmus. I am a Postdoctoral Scholar at Stanford NLP group working with  <a href="https://thashim.github.io/">Tatsunori Hashimoto</a> and <a href="https://web.stanford.edu/~jurafsky/"> Dan Jurafsky</a>. I received my PhD from Cornell University where I was advised by <a href="https://www.cs.cornell.edu/home/cardie/">Claire Cardie</a>. 

My research interests lie at the intersection of Natural Language Processing, Machine Learning, and Computational Social Science. I am interested in developing evaluation methods and metrics to study the reliability and social impact of NLP/AI systems. I also explore social applications of NLP, such as understanding the dynamics of persuasion and characteristics of constructive race conversations on social media platforms.

<h2>News</h2>
<ul>
    <li> June 2020: I joined Stanford NLP as a Postdoc.</li>
    <li> July 2020: I am co-teaching CS4740 in Fall 2020.</li>
    <li> Jan 2020: I am interning at Google AI Research in Summer 2020.</li>
    <li> Sep 2019: Selected as one of the Rising Stars in EECS 2019 by UIUC.</li>

</ul>


<h2>Publications</h2>

<ol type="1">
       <li>
        <b>Easily Accessible Text-to-Image Generation Amplifies Demographic Stereotypes at Large Scale</b>
        <br /> Federico Bianchi, Pratyusha Kalluri,<b> Esin Durmus</b>, Faisal Ladhak, Myra Cheng, Debora Nozza, Tatsunori Hashimoto, Dan Jurafsky, James Zou, Aylin Caliskan <br />
       Preprint, 2022. <br />
        [<a href="https://arxiv.org/abs/2211.03759">paper</a>] <br />
    </li>
   <br />
     <li>
        <b>Holistic Evaluation of Language Models</b>  <br />
        Preprint, 2022. <br />
        [<a href="https://arxiv.org/pdf/2211.09110.pdf">paper</a>] <br />
    </li>
        <br />
       <li>
        <b>Improving Faithfulness by Augmenting Negative Summaries from Fake Documents</b>
        <br /> Tianshu Wang, Faisal Ladhak,<b> Esin Durmus</b>, He He <br />
       To appear in EMNLP 2022. <br />
    </li>
      <br />
   <li>
        <b>Spurious Correlations in Reference-Free Evaluation of Text Generation</b>
        <br /> <b> Esin Durmus</b>, Faisal Ladhak, Tatsunori Hashimoto <br />
        In Proceedings of ACL 2022 Main conference. <br />
        [<a href="https://aclanthology.org/2022.acl-long.102/">paper</a>] <br />
    </li>
    <br />
    <li>
        <b>Faithful or Extractive? On Mitigating the Faithfulness-Abstractiveness Trade-off in Abstractive Summarization</b>
        <br /> Faisal Ladhak, <b> Esin Durmus</b>, He He, Claire Cardie, Kathleen McKeown <br />
        In Proceedings of ACL 2022 Main conference. <br />
        [<a href="https://aclanthology.org/2022.acl-long.100/">paper</a>] <br />
    </li>
    <br />
    <li>
        <b>Language Modeling via Stochastic Processes</b>
        <br /> Rose E Wang, <b> Esin Durmus</b>, Noah Goodman, Tatsunori Hashimoto <br />
        In Proceedings of ICLR 2022. <br />
        [<a href="https://openreview.net/forum?id=pMQwKL1yctf">paper</a>] <br />
    </li>
     <br />
    <li>
        <b>On the Opportunities and Risks of Foundation Models</b><br />
        [<a href="https://arxiv.org/pdf/2108.07258.pdf">paper</a>]
        [<a href="publications/opportunities.bib">bib</a>]
    </li>
    <br />
    <li>
        <b>Towards Understanding Persuasion in Computational Argumentation</b><br />
        PhD Dissertation<br />
        [<a href="https://ecommons.cornell.edu/handle/1813/109733">paper</a>]
        [<a href="publications/thesis.bib">bib</a>]
    </li>
    <br />
    <li>
        <b>Leveraging Topic Relatedness for Argument Persuasion</b>
         <br />Xinran Zhao, <b>Esin Durmus</b>, Hongming Zhang, Claire Cardie <br />
         In Findings of ACL, 2021. <br />
        [<a href="https://aclanthology.org/2021.findings-acl.386.pdf">paper</a>]       
        [<a href="publications/topic_relatedness.bib">bib</a>]
    </li>
    <br />
    <li>
        <b>The Gem Benchmark: Natural Language Generation, its Evaluation and Metrics </b><br />
        [<a href="https://gem-benchmark.com/team">Team</a>]
        [<a href="https://arxiv.org/abs/2102.01672">paper</a>]
        [<a href="publications/gem.bib">bib</a>]
        [<a href="https://gem-benchmark.com">website</a>]
    </li>
    <br />
    <li>
        <b>WikiLingua: A New Benchmark Dataset for Cross-Lingual Abstractive Summarization </b><br />
        Faisal Ladhak, <b>Esin Durmus </b>, Claire Cardie and Kathleen McKeown. <br />
        In Findings of EMNLP, 2020. <br />
        [<a href="https://aclanthology.org/2020.findings-emnlp.360">paper</a>]
        [<a href="https://github.com/esdurmus/Wikilingua">data</a>]
        [<a href="publications/wikilingua.bib">bib</a>]
    </li>
    <br />
    <li><b>Exploring the Role of Argument Structure in Online Debate Persuasion</b><br />
        Jialu Li, <b>Esin Durmus</b> and Claire Cardie.<br />
        In Proceedings of EMNLP, 2020. <br />
        [<a href="https://aclanthology.org/2020.emnlp-main.716">paper</a>]
        [<a href="publications/arg_struc_pers.bib">bib</a>]
    </li>
    <br />
    <li><b>FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive
        Summarization</b><br />
        <b>Esin Durmus</b>, He He and Mona Diab. <br />
        In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL),
        2020. <br />
        [<a href="https://aclanthology.org/2020.acl-main.454.pdf">paper</a>]
        [<a href="https://github.com/esdurmus/feqa">code</a>]
        [<a href="publications/feqa.bib">bib</a>]
    </li>
    <br />
    <li><b>The Role of Pragmatic and Discourse Context in Determining Argument Impact</b><br />
        <b>Esin Durmus</b>, Faisal Ladhak and Claire Cardie. <br />
        In Proceedings of the Conference on Empirical Methods in Natural Language Processing
        (EMNLP), 2019. <br />
        [<a href="https://aclanthology.org/D19-1568/">paper</a>]
        [<a href="publications/arg_impact.bib">bib</a>]
    </li>
    <br />
    <li>
        <b> Determining Relative Argument Specificity and Stance for Complex Argumentative
            Structures </b>
        <br />
        <b>Esin Durmus</b>, Faisal Ladhak and Claire Cardie. <br />
        In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics
        (ACL), 2019. <br />
        [<a href="https://aclanthology.org/P19-1456/">paper</a>]
        [<a href="publications/arg_struc.bib">bib</a>]
    </li>
    <br />
    <li>
        <b>A Corpus for Modeling User and Language Effects in Argumentation on Online Debating</b>
        <br />
        <b>Esin Durmus</b> and Claire Cardie. <br />
        In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics
        (ACL), 2019. <br />
        [<a href="https://aclanthology.org/P19-1057">paper</a>]
        [<a href="publications/debate_corpus.bib">bib</a>]
        [<a href="ddo.md">dataset</a>]
    </li>
    <br />
    <li>
        <b>Persuasion of the Undecided: Language vs. the Listener </b><br />
        Liane Longpre, <b>Esin Durmus</b> and Claire Cardie. <br />
        In Proceedings of the 6th Workshop in Argumentation Mining 2019. <br />
        [<a href="https://aclanthology.org/W19-4519">paper</a>]
        [<a href="publications/debate_undecided.bib">bib</a>]
        [<a href="ddo.md">dataset</a>]
    </li>
    <br />
    <li>
        <b> Modeling the Factors of User Success in Online Debate </b> <br />
        <b>Esin Durmus</b> and Claire Cardie. <br />
        In Proceedings of the World Wide Web Conference (WWW), 2019. <br />
        [<a href="https://dl.acm.org/doi/10.1145/3308558.3313676">paper</a>]
        [<a href="publications/modeling_factors.bib">bib</a>]
        [<a href="ddo.md">dataset</a>]
        <br />
        <a href="https://news.cornell.edu/stories/2019/05/win-online-debates-social-networks-worth-thousand-words">
            <b>Cornell Chronicle Story</b> </a><br />
    </li>
    <br />
    <li>
        <b>Exploring the Role of Prior Beliefs for Argument Persuasion</b><br />
        <b>Esin Durmus</b> and Claire Cardie. <br />
        In Proceedings of the Conference of the North American Chapter of the Association for
        Computational Linguistics: Human Language Technologies (NAACL), 2018. <br />
        [<a href="https://aclanthology.org/N18-1094/">paper</a>]
        [<a href="publications/prior_beliefs.bib">bib</a>]
        [<a href="ddo.md">dataset</a>]
    </li>
    <br />
    <li>
        <b>Understanding the Effect of Gender and Stance on Opinion Expression in Debates on
            "Abortion‚Äù.</b> <br />
        <b>Esin Durmus</b> and Claire Cardie. <br />
        In Proceedings of PEOPLES2018 workshop (co-organized with NAACL) on computational modeling
        of peoples opinions, personality, and emotions in social media. <br />
        [<a href="https://aclanthology.org/W18-1110">paper</a>]
        [<a href="publications/abortion.bib">bib</a>]
    </li>
    <br />
    <li><b>Cornell Belief and Sentiment System at TAC 2016 </b><br />
        Vlad Niculae, Kai Sun, Xilun Chen, Yao Cheng, Xinya Du,<b> Esin Durmus</b>, Arzoo Katiyar
        and Claire Cardie. <br />
        Text Analysis Conference (TAC), 2016. <br />
        [<a href="publications/tac.pdf">paper</a>]
        [<a href="publications/tac.bib">bib</a>]
    </li>
</ol>

<h2>Published Datasets</h2>
<ul>
    <li>
        <b><a href="https://github.com/esdurmus/Wikilingua">WikiLingua</a></b></li>
    <li><b><a
            href="ddo.html"> DDO (Debate.org) corpus</a></b></li>
    <li>
        <b>Kialo Dataset:</b> get access via <a href="mailto:esdurmus@stanford.edu">email</a>.
    </li>
</ul>
           
<h2>Teaching</h2>
<ul>
    <li><b>Instructor</b> for Introduction to Natural Language Processing, Cornell University. Fall
        2020.
    </li>
    <li><b>Teaching Assistant</b> for Introduction to Natural Language Processing, Cornell
        University. Fall 2016, Fall 2017, Fall 2019.
    </li>
    <li><b>Teaching Assistant</b> for Machine Learning for Data Science, Cornell University. Spring
        2016.
    </li>
    <li><b>Teaching Assistant </b> for Introduction to Web Design, Cornell University. Fall 2015.
    </li>
</ul>

<h2>Industry Experience</h2>
<ul>
    <li> Research Intern in Google AI Research. Summer 2020 - December 2020.</li>
    <li> Applied Scientist Intern in Amazon AWS. Summer 2019 - December 2019.</li>
    <li>Applied Scientist Intern in Amazon Alexa. Summer 2017.</li>
</ul>

